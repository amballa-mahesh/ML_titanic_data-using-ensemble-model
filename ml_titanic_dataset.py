# -*- coding: utf-8 -*-
"""ML_titanic_dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-EY8sXoPPoIyUyVZt_1bTzQfJOk7fJi8
"""

import pandas as pd

"""Reading Data"""

df_train = pd.read_csv('/content/train.csv')

df_train.info()

df_train.head(5)

"""Removing Unnecessary columns"""

df_train.drop(['PassengerId','Name','Ticket','Fare',"Cabin"],axis=1,inplace =True)

df_train.replace_index =True

df_train.head()

df_train.info()

"""Imputing Missing Values"""

mode_Embarked = df_train['Embarked'].mode()
mode_Embarked[0]

df_train['Embarked'].fillna(mode_Embarked[0],inplace =True)

df_train.info()

import numpy as np

age_female = round(df_train['Age'][df_train['Sex']=='female'].mean(),2)
age_male   = round(df_train['Age'][df_train['Sex']=='male'].mean(),2)
age_male,age_female

df_train['Age'].fillna('',inplace =True)

for i in range(0,df_train.shape[0]):
  if df_train.loc[i,'Sex']=='female' and df_train.loc[i,'Age']=='':
    df_train.loc[i,'Age'] = age_female
  elif df_train.loc[i,'Sex']=='male' and df_train.loc[i,'Age']=='':
    df_train.loc[i,'Age'] = age_male

df_train['Age'] = df_train['Age'].astype('float')

df_train.head()

"""Creating OneHot Encoding"""

df_train = pd.get_dummies(df_train,columns= ['Pclass','Embarked','SibSp','Parch'],drop_first =True)

df_train['Sex'].replace({'male':0,'female':1},inplace=True)

df_train.head()

"""Treating Outliers"""

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(4,3))
sns.boxplot(df_train['Age'],orient ='h')
plt.show()

age_q1 = np.percentile(df_train['Age'],25)
age_q3 = np.percentile(df_train['Age'],75)
age_iqr = age_q3 - age_q1
lw_limit = age_q1-(1.5*age_iqr)
up_limit = age_q3+(1.5*age_iqr)

lw_limit,up_limit

for i in range(0,df_train.shape[0]):
  if df_train.loc[i,'Age'] < lw_limit:
    df_train.loc[i,'Age'] = lw_limit
  if df_train.loc[i,'Age'] > up_limit:
    df_train.loc[i,'Age']  = up_limit

plt.figure(figsize=(4,3))
sns.boxplot(df_train['Age'],orient ='h')

"""Scaling the data using MinMax Scaling"""

from sklearn.preprocessing import MinMaxScaler
scaler= MinMaxScaler()

scaler_age = np.round(scaler.fit_transform(np.array(df_train['Age']).reshape(-1,1)),4)

df_train['Age'] = scaler_age

df_train.head()

"""Spliting the data into Dependent and Independent Variables"""

X = df_train.drop('Survived',axis = 1, inplace =False)
y = df_train['Survived']

X.head()

"""# Creation of Model Using GridsearchCV for hypertunning the parameters, and ROC curve, AUC for finding the thershold.(Logistic Regression)"""

from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix

x_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state =123,stratify =y)

estimator = LogisticRegression()
C = np.array([0.0000001,0.00001,0.0001,0.001,0.01,0.1,1,10,100])
param_grid = {'C':C}
neigh = GridSearchCV(estimator,param_grid,cv = 5,scoring= "roc_auc",return_train_score=True,verbose =2)

neigh.fit(x_train,y_train)

neigh.best_params_

neigh.best_params_['C']

results = pd.DataFrame.from_dict(neigh.cv_results_)

results

train_score = results['mean_train_score']
test_score  = results['mean_test_score']
C_values    = results['param_C']

plt.figure(figsize=(4,3))
plt.plot(C_values,train_score,label = "Train_score")
plt.plot(C_values,test_score,label = "Test_score")
plt.grid()
plt.legend()
plt.show()
print('best_C : ',neigh.best_params_)
print('best_score:', neigh.best_score_)

from sklearn.metrics import roc_curve, auc

neigh = LogisticRegression(C= neigh.best_params_['C'],penalty='l2')
neigh.fit(x_train,y_train)

y_train_pred = neigh.predict_log_proba(x_train)[:,1]
y_test_pred  = neigh.predict_log_proba(x_test)[:,1]

tr_fpr,tr_tpr,tr_thershold = roc_curve(y_train,y_train_pred)
ts_fpr,ts_tpr,ts_thershold = roc_curve(y_test,y_test_pred)

plt.figure(figsize=(4,3))
plt.plot(tr_fpr,tr_tpr,label = 'train_auc: '+ str(auc(tr_fpr,tr_tpr)))
plt.plot(ts_fpr,ts_tpr,label = 'test_auc: '+ str(auc(ts_fpr,ts_tpr)))
plt.xlabel('FPR---->')
plt.ylabel('TPR---->')
plt.grid()
plt.legend()
plt.show()

tr_ther = tr_thershold[np.argmax([tr_tpr*(1-tr_fpr)])]
tr_ther

train_preds = []
for i in y_train_pred:
  if i>=tr_ther:
    train_preds.append(1)
  else:
    train_preds.append(0)

print(accuracy_score(y_train,train_preds))
print(confusion_matrix(y_train,train_preds))

ts_ther = ts_thershold[np.argmax([ts_tpr*(1-ts_fpr)])]
ts_ther

test_preds = []
for i in y_test_pred:
  if i>=ts_ther:
    test_preds.append(1)
  else:
    test_preds.append(0)

print(accuracy_score(y_test,test_preds))
print(confusion_matrix(y_test,test_preds))

scores= dict()
score_lr = accuracy_score(y_test,test_preds)
score_lr
scores['Logistic_regression']= round(score_lr,2)

"""# Creation of Model Using GridsearchCV for hypertunning the parameters, and ROC curve, AUC for finding the thershold.(MultinomialNB)"""

from sklearn.naive_bayes import MultinomialNB

estimator = MultinomialNB()
alphas = np.array([0.00001,0.0001,0.001,0.01,0.1,1,2,3,4,5,6,10,40,50,100])
param_grid = {'alpha':alphas}
neigh  = GridSearchCV(estimator,param_grid,cv= 5,scoring = 'roc_auc',return_train_score =True,verbose = 1)

neigh.fit(x_train,y_train)

neigh.best_params_

results = pd.DataFrame.from_dict(neigh.cv_results_)

results

train_score = results['mean_train_score']
test_score  = results['mean_test_score']
alpha_values= results['param_alpha']

plt.figure(figsize=(4,3))
plt.plot(alpha_values,train_score,label= 'Train_score')
plt.plot(alpha_values,test_score, label= 'Test_score' )
plt.legend()
plt.grid()
plt.show()
print('best alphas value is: ',neigh.best_params_)

neigh = MultinomialNB(alpha=neigh.best_params_['alpha'])
neigh.fit(x_train,y_train)

y_train_pred = neigh.predict_log_proba(x_train)[:,1]
y_test_pred  = neigh.predict_log_proba(x_test)[:,1]

tr_fpr,tr_tpr,tr_thershold = roc_curve(y_train,y_train_pred)
ts_fpr,ts_tpr,ts_thershold = roc_curve(y_test,y_test_pred)

plt.figure(figsize=(4,3))
plt.plot(tr_fpr,tr_tpr,label = 'train_auc: '+ str(auc(tr_fpr,tr_tpr)))
plt.plot(ts_fpr,ts_tpr,label = 'test_auc: '+ str(auc(ts_fpr,ts_tpr)))
plt.xlabel('FPR---->')
plt.ylabel('TPR---->')
plt.grid()
plt.legend()
plt.show()

tr_ther = tr_thershold[np.argmax((tr_tpr*(1-tr_fpr)))]
tr_ther

train_preds = []
for i in y_train_pred:
  if i>=tr_ther:
    train_preds.append(1)
  else:
    train_preds.append(0)

print(accuracy_score(y_train,train_preds))

ts_ther = ts_thershold[np.argmax((ts_tpr*(1-ts_fpr)))]
ts_ther

test_preds = []
for i in y_test_pred:
  if i>=ts_ther:
    test_preds.append(1)
  else:
    test_preds.append(0)

print(accuracy_score(y_test,test_preds))

score_nb = accuracy_score(y_test,test_preds)
scores['Naive_bayes']= round(score_nb,2)

"""# Creation of Model Using GridsearchCV for hypertunning the parameters, and ROC curve, AUC for finding the thershold.(Support Vector Machine)"""

from sklearn.svm import SVC

estimator = SVC()
C      = np.array([0.0000001,0.00001,0.0001,0.001,0.01,0.1,1])
gamma  = np.array([0.0000001,0.00001,0.0001,0.001,0.01,0.1,1])
kernel = ['poly','rbf']
degree = np.array([1,2,3])
param_grid = {'C':C,"gamma":gamma,'kernel':kernel,'degree':degree}
neigh = GridSearchCV(estimator,param_grid,cv = 5,scoring ='roc_auc',return_train_score=True,verbose = 2)

neigh.fit(x_train,y_train)

neigh.best_params_

results = pd.DataFrame.from_dict(neigh.cv_results_)
results.head()

train_score = results['mean_train_score']
test_score  = results['mean_test_score']
alpha_values= results['param_C']

plt.figure(figsize=(4,3))
plt.plot(alpha_values,train_score,label= 'Train_score')
plt.plot(alpha_values,test_score, label= 'Test_score' )
plt.legend()
plt.grid()
plt.show()
print('best alphas value is: ',neigh.best_params_)

neigh =SVC(gamma=neigh.best_params_['gamma'],k
           ernel =neigh.best_params_['kernel'],
           degree = neigh.best_params_['degree'],
           C=neigh.best_params_['C'],probability=True)
neigh.fit(x_train,y_train)

y_train_pred = neigh.predict_log_proba(x_train)[:,1]
y_test_pred  = neigh.predict_log_proba(x_test)[:,1]

tr_fpr,tr_tpr,tr_thershold = roc_curve(y_train,y_train_pred)
ts_fpr,ts_tpr,ts_thershold = roc_curve(y_test,y_test_pred)

plt.figure(figsize=(4,3))
plt.plot(tr_fpr,tr_tpr,label = 'train_auc: '+ str(auc(tr_fpr,tr_tpr)))
plt.plot(ts_fpr,ts_tpr,label = 'test_auc: '+ str(auc(ts_fpr,ts_tpr)))
plt.xlabel('FPR---->')
plt.ylabel('TPR---->')
plt.grid()
plt.legend()
plt.show()

tr_ther = tr_thershold[np.argmax([tr_tpr*(1-tr_fpr)])]
tr_ther

train_preds = []
for i in y_train_pred:
  if i>=tr_ther:
    train_preds.append(1)
  else:
    train_preds.append(0)

print(accuracy_score(y_train,train_preds))

ts_ther = ts_thershold[np.argmax((ts_tpr*(1-ts_fpr)))]
ts_ther

test_preds = []
for i in y_test_pred:
  if i>=ts_ther:
    test_preds.append(1)
  else:
    test_preds.append(0)

print(accuracy_score(y_test,test_preds))

score_svc = accuracy_score(y_test,test_preds)
scores['SVC'] = round(score_svc,2)

"""# Creation of Model Using GridsearchCV for hypertunning the parameters, and ROC curve, AUC for finding the thershold.(Decision Tree)"""

from sklearn.tree import DecisionTreeClassifier

estimator = DecisionTreeClassifier()
min_samples_split = np.array([3,5,7,9,11,15])
max_leaf_nodes   = np.array([5,10,15,20,25,30,35])
param_grid = {'min_samples_split':min_samples_split,'max_leaf_nodes':max_leaf_nodes}
neigh  = GridSearchCV(estimator,param_grid,cv =5, scoring ='roc_auc',return_train_score =True,verbose =2)

neigh.fit(x_train,y_train)

neigh.best_params_

results = pd.DataFrame.from_dict(neigh.cv_results_)

results.head()

train_score = results['mean_train_score']
test_score  = results['mean_test_score']
alpha_values= results['param_max_leaf_nodes']

plt.figure(figsize=(4,3))
plt.plot(alpha_values,train_score,label= 'Train_score')
plt.plot(alpha_values,test_score, label= 'Test_score' )
plt.legend()
plt.grid()
plt.show()
print('best alphas value is: ',neigh.best_params_)

train_score = results['mean_train_score']
test_score  = results['mean_test_score']
alpha_values= results['param_min_samples_split']

plt.figure(figsize=(4,3))
plt.plot(alpha_values,train_score,label= 'Train_score')
plt.plot(alpha_values,test_score, label= 'Test_score' )
plt.legend()
plt.grid()
plt.show()
print('best alphas value is: ',neigh.best_params_)

neigh = DecisionTreeClassifier(max_leaf_nodes =neigh.best_params_['max_leaf_nodes'],
                               min_samples_split=neigh.best_params_['min_samples_split'])
neigh.fit(x_train,y_train)

y_train_pred = neigh.predict_log_proba(x_train)[:,1]
y_test_pred  = neigh.predict_log_proba(x_test)[:,1]

tr_fpr,tr_tpr,tr_thershold = roc_curve(y_train,y_train_pred)
ts_fpr,ts_tpr,ts_thershold = roc_curve(y_test,y_test_pred)

plt.figure(figsize=(4,3))
plt.plot(tr_fpr,tr_tpr,label = 'train_auc: '+ str(auc(tr_fpr,tr_tpr)))
plt.plot(ts_fpr,ts_tpr,label = 'test_auc: '+ str(auc(ts_fpr,ts_tpr)))
plt.xlabel('FPR---->')
plt.ylabel('TPR---->')
plt.grid()
plt.legend()
plt.show()

tr_ther = tr_thershold[np.argmax([tr_tpr*(1-tr_fpr)])]
tr_ther

train_preds = []
for i in y_train_pred:
  if i>=tr_ther:
    train_preds.append(1)
  else:
    train_preds.append(0)

print(accuracy_score(y_train,train_preds))

ts_ther = ts_thershold[np.argmax((ts_tpr*(1-ts_fpr)))]
ts_ther

test_preds = []
for i in y_test_pred:
  if i>=ts_ther:
    test_preds.append(1)
  else:
    test_preds.append(0)

print(accuracy_score(y_test,test_preds))

score_dt = accuracy_score(y_test,test_preds)
scores['Decision_tree'] = round(score_dt,2)

"""# Creation of Model Using GridsearchCV for hypertunning the parameters, and ROC curve, AUC for finding the thershold.(Random Forest)"""

from sklearn.ensemble import RandomForestClassifier

estimator = RandomForestClassifier()
min_samples_split = np.array([3,5,7,9,11,15])
max_leaf_nodes    = np.array([5,10,15,20,25,30,35])
n_estimators      = np.array([25,30,35,50,75,100,150])
param_grid = {'min_samples_split':min_samples_split,'max_leaf_nodes':max_leaf_nodes,'n_estimators':n_estimators}
neigh  = GridSearchCV(estimator,param_grid,cv =5, scoring ='roc_auc',return_train_score =True,verbose =2)

neigh.fit(x_train,y_train)

neigh.best_params_

results = pd.DataFrame.from_dict(neigh.cv_results_)
results.head()

train_score = results['mean_train_score']
test_score  = results['mean_test_score']
alpha_values= results['param_n_estimators']

plt.figure(figsize=(4,3))
plt.plot(alpha_values,train_score,label= 'Train_score')
plt.plot(alpha_values,test_score, label= 'Test_score' )
plt.legend()
plt.grid()
plt.show()
print('best alphas value is: ',neigh.best_params_)

neigh = RandomForestClassifier(max_leaf_nodes =neigh.best_params_['max_leaf_nodes'],
                               min_samples_split=neigh.best_params_['min_samples_split'],
                               n_estimators=neigh.best_params_['n_estimators'])
neigh.fit(x_train,y_train)

y_train_pred = neigh.predict_log_proba(x_train)[:,1]
y_test_pred  = neigh.predict_log_proba(x_test)[:,1]

tr_fpr,tr_tpr,tr_thershold = roc_curve(y_train,y_train_pred)
ts_fpr,ts_tpr,ts_thershold = roc_curve(y_test,y_test_pred)

plt.figure(figsize=(4,3))
plt.plot(tr_fpr,tr_tpr,label = 'train_auc: '+ str(auc(tr_fpr,tr_tpr)))
plt.plot(ts_fpr,ts_tpr,label = 'test_auc: '+ str(auc(ts_fpr,ts_tpr)))
plt.xlabel('FPR---->')
plt.ylabel('TPR---->')
plt.grid()
plt.legend()
plt.show()

tr_ther = tr_thershold[np.argmax([tr_tpr*(1-tr_fpr)])]
tr_ther

train_preds = []
for i in y_train_pred:
  if i>=tr_ther:
    train_preds.append(1)
  else:
    train_preds.append(0)

print(accuracy_score(y_train,train_preds))

ts_ther = ts_thershold[np.argmax((ts_tpr*(1-ts_fpr)))]
ts_ther

test_preds = []
for i in y_test_pred:
  if i>=ts_ther:
    test_preds.append(1)
  else:
    test_preds.append(0)

print(accuracy_score(y_test,test_preds))

score_rf = accuracy_score(y_test,test_preds)
scores['Random_forest'] = round(score_rf,2)

"""# Creation of Model Using GridsearchCV for hypertunning the parameters, and ROC curve, AUC for finding the thershold.(SGD Classifier)"""

from sklearn.linear_model import SGDClassifier

estimator = SGDClassifier(penalty='l2',loss='log',max_iter=500)
alphas =np.array([0.00001,0.0001,0.001,0.01,0.1,1,10,100])
param_grid = {'alpha':alphas}
neigh  = GridSearchCV(estimator,param_grid,cv = 5,scoring = 'roc_auc',return_train_score =True,verbose=2)

neigh.fit(x_train,y_train)

neigh.best_params_

results = pd.DataFrame.from_dict(neigh.cv_results_)
results.head()

train_score = results['mean_train_score']
test_score  = results['mean_test_score']
alpha_values= results['param_alpha']

plt.figure(figsize=(4,3))
plt.plot(alpha_values,train_score,label= 'Train_score')
plt.plot(alpha_values,test_score, label= 'Test_score' )
plt.legend()
plt.grid()
plt.show()
print('best alphas value is: ',neigh.best_params_)

neigh = SGDClassifier(penalty='l2',loss='log',max_iter=500,alpha =neigh.best_params_['alpha'])
neigh.fit(x_train,y_train)

y_train_pred = neigh.predict_log_proba(x_train)[:,1]
y_test_pred  = neigh.predict_log_proba(x_test)[:,1]

tr_fpr,tr_tpr,tr_thershold = roc_curve(y_train,y_train_pred)
ts_fpr,ts_tpr,ts_thershold = roc_curve(y_test,y_test_pred)

plt.figure(figsize=(4,3))
plt.plot(tr_fpr,tr_tpr,label = 'train_auc: '+ str(auc(tr_fpr,tr_tpr)))
plt.plot(ts_fpr,ts_tpr,label = 'test_auc: '+ str(auc(ts_fpr,ts_tpr)))
plt.xlabel('FPR---->')
plt.ylabel('TPR---->')
plt.grid()
plt.legend()
plt.show()

tr_ther = tr_thershold[np.argmax([tr_tpr*(1-tr_fpr)])]
tr_ther

train_preds = []
for i in y_train_pred:
  if i>=tr_ther:
    train_preds.append(1)
  else:
    train_preds.append(0)

print(accuracy_score(y_train,train_preds))

ts_ther = ts_thershold[np.argmax((ts_tpr*(1-ts_fpr)))]
ts_ther

test_preds = []
for i in y_test_pred:
  if i>=ts_ther:
    test_preds.append(1)
  else:
    test_preds.append(0)

print(accuracy_score(y_test,test_preds))

score_sgd = accuracy_score(y_test,test_preds)
scores['SGD'] = round(score_sgd,2)

"""# *Visualizing the Modle Scores*"""

plt.figure(figsize= (10,4))
plt.bar(scores.keys(),scores.values())
plt.grid()
plt.show()

"""# *Creation of the Ensemble Model using all the above Models*"""

from sklearn.ensemble import VotingClassifier

model1 = DecisionTreeClassifier(max_leaf_nodes=10, min_samples_split=3)
model2 = RandomForestClassifier(max_leaf_nodes=25, min_samples_split=15, n_estimators=25)
model3 = LogisticRegression(C= 10.0,penalty='l2')
model4 = MultinomialNB(alpha= 1.0)
model5 = SGDClassifier(penalty='l2',loss='log',max_iter=500,alpha =0.001)
model6 = SVC(C=0.1, degree=2, gamma=1.0, kernel='poly', probability=True)

estimators_all = [('DT', model1),('RF', model2),('LG', model3),('NB', model4),('SGD', model5),('SVC', model6)]

model_final = VotingClassifier(estimators = estimators_all, voting='hard')

model_final.fit(x_train,y_train)

y_pred = model_final.predict(x_test)

"""# **Final Ensemble model performance**"""

print(accuracy_score(y_test,y_pred))

print(confusion_matrix(y_test,y_pred))

print(classification_report(y_test,y_pred))